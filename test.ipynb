{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 256, 256]) + torch.Size([1, 3, 256, 256]) -> torch.Size([1, 1, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Класс Discriminator представляет собой сверточную нейронную сеть, используемую для различения изображений.\n",
    "    \n",
    "    Аргументы:\n",
    "    in_channels (int): Количество входных каналов. По умолчанию 4 (1 канал для источника и 3 канала для цели).\n",
    "    \n",
    "    Методы:\n",
    "    __init__(self, in_channels=4): Инициализирует слои дискриминатора.\n",
    "    forward(self, src, target): Выполняет прямое распространение через сеть. Объединяет входные изображения (src и target) по каналу и пропускает их через модель.\n",
    "    \n",
    "    Пример использования:\n",
    "    discriminator = Discriminator()\n",
    "    output = discriminator(src_image, target_image)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=5):  # 2 channel source + 3 channels target\n",
    "        super(Discriminator, self).__init__()\n",
    "        def discriminator_block(in_channels, out_channels, stride):\n",
    "            layers = [\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=stride, padding=1),\n",
    "                nn.BatchNorm2d(out_channels),  # No BN in first layer\n",
    "                nn.LeakyReLU(0.2, inplace=True)\n",
    "            ]\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            # C64: 4x4 kernel, stride 2, padding 1\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # C128: 4x4 kernel, stride 2, padding 1\n",
    "            *discriminator_block(64, 128, stride=2),\n",
    "\n",
    "            # C256: 4x4 kernel, stride 2, padding 1\n",
    "            *discriminator_block(128, 256, stride=2),\n",
    "\n",
    "            # C512: 4x4 kernel, stride 1, padding 1\n",
    "            *discriminator_block(256, 512, stride=1),\n",
    "\n",
    "            # C1: 4x4 kernel, stride 1, padding 1\n",
    "            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1),\n",
    "\n",
    "            # Sigmoid activation\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, src, target):\n",
    "        x = torch.cat((src, target), dim=1)\n",
    "        return self.model(x)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    D = Discriminator()\n",
    "    x = torch.randn(1, 2, 256, 256)\n",
    "    target = torch.randn(1, 3, 256, 256)\n",
    "    print(f'{x.shape} + {target.shape} -> {D(x, target).shape}')  # torch.Size([1, 1, 30, 30])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 256, 256]) -> torch.Size([1, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "class UNetGenerator(nn.Module):\n",
    "    def __init__(self, input_channels=2, output_channels=3):\n",
    "        super(UNetGenerator, self).__init__()\n",
    "        \n",
    "        def encoder_block(in_channels, out_channels, use_bn=True):\n",
    "            layers = [\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1),\n",
    "                nn.LeakyReLU(0.2, inplace=True)\n",
    "            ]\n",
    "            if use_bn:\n",
    "                layers.append(nn.BatchNorm2d(out_channels))\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        def decoder_block(in_channels, out_channels, dropout=0):\n",
    "            layers = [\n",
    "                nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            ]\n",
    "            if dropout != 0:\n",
    "                layers.append(nn.Dropout(dropout))\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        def bottleneck_block(in_channels, out_channels):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "\n",
    "        # Encoder\n",
    "        self.enc1 = encoder_block(input_channels, 64, use_bn=False)\n",
    "        self.enc2 = encoder_block(64, 128)\n",
    "        self.enc3 = encoder_block(128, 256)\n",
    "        self.enc4 = encoder_block(256, 512)\n",
    "        self.enc5 = encoder_block(512, 512)\n",
    "        self.enc6 = encoder_block(512, 512)\n",
    "        self.enc7 = encoder_block(512, 512)\n",
    "\n",
    "        self.bottleneck = bottleneck_block(512, 512)\n",
    "\n",
    "        # Decoder\n",
    "        self.dec1 = decoder_block(512, 512, dropout=0.5)\n",
    "        self.dec2 = decoder_block(1024, 512, dropout=0.5)\n",
    "        self.dec3 = decoder_block(1024, 512, dropout=0.5)\n",
    "        self.dec4 = decoder_block(1024, 512)\n",
    "        self.dec5 = decoder_block(1024, 256)\n",
    "        self.dec6 = decoder_block(512, 128)\n",
    "        self.dec7 = decoder_block(256, 64)\n",
    "        self.final = nn.ConvTranspose2d(128, output_channels, kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(e1)\n",
    "        e3 = self.enc3(e2)\n",
    "        e4 = self.enc4(e3)\n",
    "        e5 = self.enc5(e4)\n",
    "        e6 = self.enc6(e5)\n",
    "        e7 = self.enc7(e6)\n",
    "\n",
    "        b = self.bottleneck(e7)\n",
    "\n",
    "        # Decoder + Skip connections\n",
    "        d1 = self.dec1(b)\n",
    "        d2 = self.dec2(torch.cat([d1, e7], dim=1))\n",
    "        d3 = self.dec3(torch.cat([d2, e6], dim=1))\n",
    "        d4 = self.dec4(torch.cat([d3, e5], dim=1))\n",
    "        d5 = self.dec5(torch.cat([d4, e4], dim=1))\n",
    "        d6 = self.dec6(torch.cat([d5, e3], dim=1))\n",
    "        d7 = self.dec7(torch.cat([d6, e2], dim=1))\n",
    "        return torch.tanh(self.final(torch.cat([d7, e1], dim=1)))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    G = UNetGenerator()\n",
    "    x = torch.randn(1, 2, 256, 256)\n",
    "    print(f'{x.shape} -> {G(x).shape}')  # torch.Size([1, 3, 256, 256])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pix2PixGAN:\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        self.generator = UNetGenerator().to(self.device)\n",
    "        self.discriminator = Discriminator().to(self.device)\n",
    "\n",
    "        self.optimizer_G = torch.optim.AdamW(self.generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "        self.optimizer_D = torch.optim.AdamW(self.discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "        self.criterion_GAN = nn.BCEWithLogitsLoss()\n",
    "        self.criterion_L1 = nn.L1Loss()\n",
    "\n",
    "    def train_step(self, real_A, real_B):\n",
    "        real_A, real_B = real_A.to(self.device), real_B.to(self.device)\n",
    "\n",
    "        # Train Discriminator\n",
    "        self.optimizer_D.zero_grad()\n",
    "        fake_B = self.generator(real_A)\n",
    "\n",
    "        # Получаем выходные данные дискриминатора\n",
    "        output_real = self.discriminator(real_A, real_B)\n",
    "        output_fake = self.discriminator(real_A, fake_B.detach())\n",
    "\n",
    "        # Создаем целевые метки того же размера, что и выходные данные дискриминатора\n",
    "        target_real = torch.ones_like(output_real)\n",
    "        target_fake = torch.zeros_like(output_fake)\n",
    "\n",
    "        # Вычисляем потери\n",
    "        loss_D_real = self.criterion_GAN(output_real, target_real)\n",
    "        loss_D_fake = self.criterion_GAN(output_fake, target_fake)\n",
    "        loss_D = (loss_D_real + loss_D_fake) / 2\n",
    "        loss_D.backward()\n",
    "        self.optimizer_D.step()\n",
    "\n",
    "        # Train Generator\n",
    "        self.optimizer_G.zero_grad()\n",
    "        loss_G_GAN = self.criterion_GAN(self.discriminator(real_A, fake_B), torch.ones_like(output_real))\n",
    "        loss_G_L1 = self.criterion_L1(fake_B, real_B) * 100\n",
    "        loss_G = loss_G_GAN + loss_G_L1\n",
    "        loss_G.backward()\n",
    "        self.optimizer_G.step()\n",
    "\n",
    "        return loss_D.item(), loss_G.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "Чекпоинт успешно загружен: c:\\Users\\tiruu\\OneDrive\\Desktop\\sar2opt\\checkpoints/checkpoint_epoch_400.pth\n",
      "Дата сохранения: 2024-12-20T14:20:29, эпоха 400\n",
      "Файл с потерями не найден по пути: c:\\Users\\tiruu\\OneDrive\\Desktop\\sar2opt/logs/losses.npz\n"
     ]
    }
   ],
   "source": [
    "from utils.helpers import *\n",
    "from utils.lossTracker import save_losses, load_losses\n",
    "from utils.checkpointLogic import save_checkpoint, load_checkpoint\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "print(f'Using {device}')\n",
    "torch.cuda.empty_cache() if torch.cuda.is_available() else torch.mps.empty_cache() if torch.mps.is_available() else None\n",
    "model = Pix2PixGAN(device)\n",
    "\n",
    "load_model = True\n",
    "if load_model:\n",
    "    start_epoch, loss_G, loss_D = load_checkpoint('checkpoint_epoch_400', model, device)\n",
    "    losses_dict = load_losses()\n",
    "    if losses_dict:\n",
    "        g_loss = losses_dict['g_loss']\n",
    "        d_loss = losses_dict['d_loss']\n",
    "    g_loss = []\n",
    "    d_loss = []\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    g_loss = []\n",
    "    d_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42b1e887911e4644b3b6ba88b27b8089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 400/600:   0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe7e4772c235478db4b411ce1a5acdf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 401/600:   0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe366b29d224f75a7417dbca24231ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 402/600:   0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9feaf89936e54e11a23381627017101a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 403/600:   0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da2e18639a2940eb9e66fe8feff8ed2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 404/600:   0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2829b103913c4327a9a1c6f70b5c761b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 405/600:   0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f6d45bfad9547668d7989750746af0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 406/600:   0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2afbbbb26af4468a4fdf5b1335867c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 407/600:   0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da551a43fd94c149292078caa382b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 408/600:   0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417f592e04b5485f94ae10c6d617579c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 409/600:   0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38478e19fa674ba0b473357e6c4ae15e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 410/600:   0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a5ac6b8f5045f5a6911a761e0074b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 411/600:   0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c331babbeb4f4a9f81e669b825c9c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 412/600:   0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e478ccf840b44215ae8e0b95da82a0be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 413/600:   0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "end_epoch = 600\n",
    "\n",
    "for epoch in range(start_epoch, end_epoch):\n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{end_epoch}\", leave=False) as pbar:\n",
    "        for i, (real_A, real_B) in enumerate(pbar):\n",
    "            loss_D, loss_G = model.train_step(real_A, real_B)\n",
    "            pbar.set_postfix({\"Loss D\": loss_D, \"Loss G\": loss_G})\n",
    "        g_loss.append(loss_G)\n",
    "        d_loss.append(loss_D)\n",
    "\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            save_checkpoint(epoch, model, loss_G, loss_D)\n",
    "            save_losses(g_loss=g_loss, d_loss=d_loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
