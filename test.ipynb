{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tiruu\\AppData\\Roaming\\Python\\Python39\\site-packages\\albumentations\\__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.4' (you have '2.0.3'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tiruu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\tiruu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\tiruu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lpips\\lpips.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.load_state_dict(torch.load(model_path, map_location='cpu'), strict=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [squeeze], v[0.1], spatial [off]\n",
      "Loading model from: c:\\Users\\tiruu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lpips\\weights\\v0.1\\squeeze.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/400 Train:  36%|███▌      | 65/182 [00:20<00:36,  3.25it/s, Loss D=1.09, Loss G=27.8, LR D=0.000394, LR G=9.84e-5]                   "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from models.Pix2Pix_youtube import Pix2PixGAN\n",
    "from utils.Dataset import *\n",
    "from utils.lossTracker import save_losses, load_losses\n",
    "import matplotlib.gridspec as gridspec\n",
    "from utils.ConfigLoader import ConfigLoader\n",
    "config = ConfigLoader()\n",
    "import torchvision\n",
    "\n",
    "import torch.profiler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()  # Инициализация логгера\n",
    "\n",
    "def train(model, train_loader, device): \n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{end_epoch} Train\", leave=False) as pbar:\n",
    "        train_loss_G_history, train_loss_D_history, train_ssim_history, train_psnr_history = [], [], [], []\n",
    "        for real_A, real_B in pbar:\n",
    "            train_loss_G, train_loss_D, train_ssim, train_psnr = model.train_step(real_A.to(device), real_B.to(device))\n",
    "            pbar.set_postfix({\n",
    "                \"Loss D\": train_loss_D,\n",
    "                \"Loss G\": train_loss_G,\n",
    "                \"LR D\": model.optimizer_D.param_groups[0]['lr'],\n",
    "                \"LR G\": model.optimizer_G.param_groups[0]['lr'],\n",
    "            })\n",
    "            train_loss_G_history.append(train_loss_G)\n",
    "            train_loss_D_history.append(train_loss_D)\n",
    "            train_ssim_history.append(train_ssim)\n",
    "            train_psnr_history.append(train_psnr)\n",
    "    return (torch.mean(torch.tensor(train_loss_G)),\n",
    "            torch.mean(torch.tensor(train_loss_D)),\n",
    "            torch.mean(torch.tensor(train_ssim_history)),\n",
    "            torch.mean(torch.tensor(train_psnr_history)),\n",
    "            model.optimizer_G.param_groups[0]['lr'],\n",
    "            model.optimizer_D.param_groups[0]['lr'])\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, val_loader, device):\n",
    "    \"\"\"\n",
    "    Валидационный цикл для оценки модели на валидационном датасете.\n",
    "    \"\"\"\n",
    "    model.generator.eval()  # Перевод генератора в режим валидации\n",
    "    model.discriminator.eval()  # Перевод дискриминатора в режим валидации\n",
    "\n",
    "    with tqdm(val_loader, desc=f\"Epoch {epoch+1}/{end_epoch} Validation\", leave=False) as pbar:\n",
    "        val_loss_G_history, val_loss_D_history, val_ssim_history, val_psnr_history, = [], [], [], []\n",
    "        for real_A, real_B in pbar:\n",
    "            val_loss_G, val_loss_D, val_ssim, val_psnr = model.val_step(real_A, real_B)\n",
    "\n",
    "            val_loss_G_history.append(val_loss_G)\n",
    "            val_loss_D_history.append(val_loss_D)\n",
    "            val_ssim_history.append(val_ssim)\n",
    "            val_psnr_history.append(val_psnr)\n",
    "\n",
    "            pbar.set_postfix({\n",
    "                \"Val Loss G\": val_loss_G,\n",
    "                \"Val Loss D\": val_loss_D,\n",
    "                \"Val SSIM\": val_ssim,\n",
    "                \"Val PSNR\": val_psnr\n",
    "            })\n",
    "\n",
    "    return (torch.mean(torch.tensor(val_loss_G)),\n",
    "            torch.mean(torch.tensor(val_loss_D)),\n",
    "            torch.mean(torch.tensor(val_ssim_history)),\n",
    "            torch.mean(torch.tensor(val_psnr_history)))\n",
    "\n",
    "@torch.no_grad()\n",
    "def save_training_images(model, epoch, train_loss_G, train_loss_D, val_loss_G, val_loss_D, save_dir, train_fixed_sar, train_fixed_optical, val_fixed_sar, val_fixed_optical):\n",
    "    \"\"\"\n",
    "    Сохраняет графики генератора/дискриминатора потерь и фиксированные пять изображений.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Генерация фиксированных изображений\n",
    "    train_generated = model.generator(train_fixed_sar.to(device))\n",
    "    val_generated = model.generator(val_fixed_sar.to(device))\n",
    "\n",
    "    # Move tensors to CPU for visualization and ensure same device\n",
    "    train_fixed_sar = train_fixed_sar.cpu().repeat(1, 3, 1, 1)\n",
    "    train_generated = train_generated.cpu()\n",
    "    train_fixed_optical = train_fixed_optical.cpu()\n",
    "    val_fixed_sar = val_fixed_sar.cpu().repeat(1, 3, 1, 1)\n",
    "    val_generated = val_generated.cpu()\n",
    "    val_fixed_optical = val_fixed_optical.cpu()\n",
    "\n",
    "    # Log generated images to TensorBoard\n",
    "    train_grid = torchvision.utils.make_grid(\n",
    "        torch.cat([\n",
    "            train_fixed_sar, \n",
    "            train_generated,\n",
    "            train_fixed_optical\n",
    "        ], dim=0),\n",
    "        nrow=5,\n",
    "        normalize=True\n",
    "    )\n",
    "\n",
    "    val_grid = torchvision.utils.make_grid(\n",
    "        torch.cat([\n",
    "            val_fixed_sar,\n",
    "            val_generated, \n",
    "            val_fixed_optical\n",
    "        ], dim=0),\n",
    "        nrow=5, \n",
    "        normalize=True\n",
    "    )\n",
    "\n",
    "    fig = plt.figure(figsize=(30, 40))\n",
    "    gs = gridspec.GridSpec(7, 6, figure=fig)\n",
    "\n",
    "    fig.suptitle(f\"Epoch: {epoch+1}, G lr: {model.optimizer_D.param_groups[0]['lr']}, D lr: {model.optimizer_G.param_groups[0]['lr']}\", fontsize=16)  # y задает отступ сверху\n",
    "\n",
    "    # График потерь генератора\n",
    "    ax1 = fig.add_subplot(gs[0, :3])\n",
    "    ax1.plot(range(1, len(train_loss_G) + 1), train_loss_G, label=\"Train Generator Loss\", color=\"#3b82f6\")\n",
    "    ax1.set_title(\"Train Generator Loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.grid()\n",
    "    ax1.legend()\n",
    "\n",
    "    # График потерь дискриминатора\n",
    "    ax2 = fig.add_subplot(gs[1, :3])\n",
    "    ax2.plot(range(1, len(train_loss_D) + 1), train_loss_D, label=\"Train Discriminator Loss\", color=\"#ef4444\")\n",
    "    ax2.set_title(\"Train Discriminator Loss\")\n",
    "    ax2.set_xlabel(\"Epochs\")\n",
    "    ax2.set_ylabel(\"Loss\")\n",
    "    ax2.grid()\n",
    "    ax2.legend()\n",
    "\n",
    "    ax3 = fig.add_subplot(gs[0, 3:])\n",
    "    ax3.plot(range(1, len(val_loss_G) + 1), val_loss_G, label=\"Val Generator Loss\", color=\"#22c55e\")\n",
    "    ax3.set_title(\"Validation Generator Loss\")\n",
    "    ax3.set_xlabel(\"Epochs\")\n",
    "    ax3.set_ylabel(\"Loss\")\n",
    "    ax3.grid()\n",
    "    ax3.legend()\n",
    "\n",
    "    ax4 = fig.add_subplot(gs[1, 3:])\n",
    "    ax4.plot(range(1, len(val_loss_D) + 1), val_loss_D, label=\"Val Discriminator Loss\", color=\"#f59e0b\")\n",
    "    ax4.set_title(\"Validation Discriminator Loss\")\n",
    "    ax4.set_xlabel(\"Epochs\")\n",
    "    ax4.set_ylabel(\"Loss\")\n",
    "    ax4.grid()\n",
    "    ax4.legend()\n",
    "\n",
    "    # Добавляем изображения: SAR, Generated, Target\n",
    "    for i in range(5):\n",
    "        # SAR Image\n",
    "        ax_sar = fig.add_subplot(gs[2 + i, 0])\n",
    "        sar_image = train_fixed_sar[i, 0, :, :].cpu().detach().numpy()\n",
    "        ax_sar.imshow(sar_image * 0.5 + 0.5, cmap='gray')\n",
    "        ax_sar.set_title(f\"Train SAR Image {i+1}\")\n",
    "        ax_sar.axis('off')\n",
    "\n",
    "        # Generated Image\n",
    "        ax_gen = fig.add_subplot(gs[2 + i, 1])\n",
    "        generated_image = train_generated[i].permute(1, 2, 0).cpu().detach().numpy()\n",
    "        ax_gen.imshow((generated_image * 0.5 + 0.5))\n",
    "        ax_gen.set_title(f\"Train Generated Image {i+1}\")\n",
    "        ax_gen.axis('off')\n",
    "\n",
    "        # Target Image\n",
    "        ax_opt = fig.add_subplot(gs[2 + i, 2])\n",
    "        optical_image = train_fixed_optical[i].permute(1, 2, 0).cpu().detach().numpy()\n",
    "        ax_opt.imshow((optical_image * 0.5 + 0.5))\n",
    "        ax_opt.set_title(f\"Train Target Image {i+1}\")\n",
    "        ax_opt.axis('off')\n",
    "\n",
    "        # SAR Image\n",
    "        ax_sar = fig.add_subplot(gs[2 + i, 3])\n",
    "        sar_image = val_fixed_sar[i, 0, :, :].cpu().detach().numpy()\n",
    "        ax_sar.imshow(sar_image * 0.5 + 0.5, cmap='gray')\n",
    "        ax_sar.set_title(f\"Val SAR Image {i+1}\")\n",
    "        ax_sar.axis('off')\n",
    "\n",
    "        # Generated Image\n",
    "        ax_gen = fig.add_subplot(gs[2 + i, 4])\n",
    "        generated_image = val_generated[i].permute(1, 2, 0).cpu().detach().numpy()\n",
    "        ax_gen.imshow((generated_image * 0.5 + 0.5))\n",
    "        ax_gen.set_title(f\"Val Generated Image {i+1}\")\n",
    "        ax_gen.axis('off')\n",
    "\n",
    "        # Target Image\n",
    "        ax_opt = fig.add_subplot(gs[2 + i, 5])\n",
    "        optical_image = val_fixed_optical[i].permute(1, 2, 0).cpu().detach().numpy()\n",
    "        ax_opt.imshow((optical_image * 0.5 + 0.5))\n",
    "        ax_opt.set_title(f\"Val Target Image {i+1}\")\n",
    "        ax_opt.axis('off')\n",
    "\n",
    "    # Настройка расстояний между элементами\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Сохранение итогового изображения\n",
    "    save_path = os.path.join(save_dir, f\"epoch_{epoch+1}_images.png\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close(fig)\n",
    "    return train_grid, val_grid\n",
    "\n",
    "\n",
    "# Устройство для вычислений\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "print(f'Using {device}')\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "# Получаем 5 первых изображений из тренировочного загрузчика\n",
    "train_iterator = iter(train_loader)  # Создаем итератор для train_loader\n",
    "fixed_batch = next(train_iterator)  # Получаем первый batch\n",
    "train_fixed_sar, train_fixed_optical = fixed_batch[0][:5], fixed_batch[1][:5]  # Берем 5 первых изображений\n",
    "\n",
    "test_iterator = iter(test_loader)  # Создаем итератор для train_loader\n",
    "fixed_batch = next(test_iterator)  # Получаем первый batch\n",
    "val_fixed_sar, val_fixed_optical = fixed_batch[0][:5], fixed_batch[1][:5]  # Берем 5 первых изображений\n",
    "\n",
    "# Создание модели\n",
    "model = Pix2PixGAN(device)\n",
    "\n",
    "# Загрузка модели\n",
    "if config.get('model', 'load_model'):\n",
    "    start_epoch = model.load_state('checkpoint_epoch_100', device)\n",
    "    losses_dict = load_losses()\n",
    "    if losses_dict:\n",
    "        train_G_losses = list(losses_dict['train_G_losses'])\n",
    "        train_D_losses = list(losses_dict['train_D_losses'])\n",
    "        val_G_losses = list(losses_dict['val_G_losses'])\n",
    "        val_D_losses = list(losses_dict['val_D_losses'])\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    train_G_losses = []\n",
    "    train_D_losses = []\n",
    "    val_G_losses = []\n",
    "    val_D_losses = []\n",
    "\n",
    "# Конечная эпоха\n",
    "end_epoch = config.get('model', 'end_epoch')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Обучение модели\n",
    "for epoch in range(start_epoch, end_epoch):\n",
    "    train_loss_G, train_loss_D, train_ssim, train_psnr, lr_G, lr_D = train(model, train_loader, device)\n",
    "    val_loss_G, val_loss_D, val_ssim, val_psnr = validate(model, test_loader, device)\n",
    "\n",
    "    model.step_schedulers(val_loss_G, val_loss_D)\n",
    "\n",
    "    # memory_allocated = torch.cuda.memory_allocated(device) / (1024 ** 2)  # В мегабайтах\n",
    "    # memory_reserved = torch.cuda.memory_reserved(device) / (1024 ** 2)   # В мегабайтах\n",
    "\n",
    "    train_G_losses.append(train_loss_G)\n",
    "    train_D_losses.append(train_loss_D)\n",
    "    val_G_losses.append(val_loss_G)\n",
    "    val_D_losses.append(val_loss_D)\n",
    "\n",
    "    if writer:\n",
    "        writer.add_scalar(\"Train/Loss_G\", train_loss_G.item(), epoch + 1)\n",
    "        writer.add_scalar(\"Train/Loss_D\", train_loss_D.item(), epoch + 1)\n",
    "        writer.add_scalar(\"Train/PSNR\", train_psnr.item(), epoch + 1)\n",
    "        writer.add_scalar(\"Train/SSIM\", train_ssim.item(), epoch + 1)\n",
    "        writer.add_scalar(\"Train/Learning_Rate_G\", lr_G, epoch + 1)\n",
    "        writer.add_scalar(\"Train/Learning_Rate_D\", lr_D, epoch + 1)\n",
    "\n",
    "        writer.add_scalar(\"Val/Loss_G\", val_loss_G.item(), epoch + 1)\n",
    "        writer.add_scalar(\"Val/Loss_D\", val_loss_D.item(), epoch + 1)\n",
    "        writer.add_scalar(\"Val/PSNR\", val_psnr.item(), epoch + 1)\n",
    "        writer.add_scalar(\"Val/SSIM\", val_ssim.item(), epoch + 1)\n",
    "\n",
    "        # Гистограммы весов\n",
    "        # for name, param in model.generator.named_parameters():\n",
    "        #     writer.add_histogram(f'Generator/{name}', param, epoch + 1)\n",
    "\n",
    "        # Логгирование памяти в TensorBoard\n",
    "        # writer.add_scalar(\"Performance/Memory_Allocated_MB\", memory_allocated, global_step=epoch)\n",
    "        # writer.add_scalar(\"Performance/Memory_Reserved_MB\", memory_reserved, global_step=epoch)\n",
    "\n",
    "    # Сохранение модели и метрик\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        # model.save_state(epoch, save_dir=config.get('paths', 'model_save_dir'))\n",
    "        save_losses(\n",
    "            train_G_losses=train_G_losses,\n",
    "            train_D_losses=train_D_losses,\n",
    "            val_G_losses=val_G_losses,\n",
    "            val_D_losses=val_D_losses\n",
    "        )\n",
    "\n",
    "    # Сохранение изображений каждые 20 эпох\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        train_grid, val_grid = save_training_images(\n",
    "            model,\n",
    "            epoch,\n",
    "            train_G_losses,\n",
    "            train_D_losses,\n",
    "            val_G_losses,\n",
    "            val_D_losses,\n",
    "            config.get('paths', 'image_save_dir'),\n",
    "            train_fixed_sar, train_fixed_optical,\n",
    "            val_fixed_sar, val_fixed_optical\n",
    "        )\n",
    "        writer.add_image('Train/Train_Images', train_grid, global_step=epoch+1)\n",
    "        writer.add_image('Val/Val_Images', val_grid, global_step=epoch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "os.system(\"shutdown /s /t 60\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
